{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd389392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3319d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils  # Drawing helpers\n",
    "mp_pose = mp.solutions.pose  # Mediapipe Solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068143d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#pose model\n",
    "with mp_pose.Pose() as pose_tracker:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        result= pose_tracker.process(image)\n",
    "        pose_landmarks = result.pose_landmarks\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        cv2.imshow('Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pose_landmarks.landmark)[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450d19a",
   "metadata": {},
   "source": [
    "# Capture Landmarks and Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67aee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d382eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_landmarks = len(pose_landmarks.landmark)\n",
    "num_of_columns = 1 + num_of_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58187223",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_names = [\n",
    "        'nose',\n",
    "        'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "        'left_ear', 'right_ear',\n",
    "        'mouth_left', 'mouth_right',\n",
    "        'left_shoulder', 'right_shoulder',\n",
    "        'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist',\n",
    "        'left_pinky_1', 'right_pinky_1',\n",
    "        'left_index_1', 'right_index_1',\n",
    "        'left_thumb_2', 'right_thumb_2',\n",
    "        'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle',\n",
    "        'left_heel', 'right_heel',\n",
    "        'left_foot_index', 'right_foot_index',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdfccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for i, name in enumerate(landmark_names):\n",
    "    landmarks += ['{}_x'.format(name), '{}_y'.format(name), '{}_z'.format(name), '{}_v'.format(name)]\n",
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('video_coordinate.csv', mode = 'w', newline ='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8164f8",
   "metadata": {},
   "source": [
    "# Read data from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e85186",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_in_folder = 'yoga_poses_images_in'\n",
    "images_out_folder = 'yoga_poses_images_out'\n",
    "\n",
    "pose_class_names = [n for n in os.listdir(images_in_folder) if not n.startswith('.')]\n",
    "for pose_class_name in pose_class_names:\n",
    "    image_names = sorted([n for n in os.listdir(os.path.join(images_in_folder, pose_class_name)) \n",
    "                      if not n.startswith('.')])\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(os.path.join(images_out_folder, pose_class_name))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "        \n",
    "    for image_name in tqdm.tqdm(image_names, position=0):\n",
    "        input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
    "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      # Initialize fresh pose tracker and run it.\n",
    "        with mp_pose.Pose() as pose_tracker:\n",
    "            result = pose_tracker.process(image=input_frame)\n",
    "            pose_landmarks = result.pose_landmarks\n",
    "        \n",
    "    #write the data to a csv\n",
    "        if pose_landmarks is not None:\n",
    "            pose = pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            pose_row.insert(0, pose_class_name)\n",
    "        \n",
    "            try:\n",
    "                with open('coordinate.csv', mode = 'a', newline ='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pose_row)\n",
    "            except Exception as e:\n",
    "                print(\"An error occured\", e)\n",
    "        \n",
    "    # Save image with pose prediction (if pose was detected).\n",
    "        output_frame = input_frame.copy()\n",
    "        if pose_landmarks is not None:\n",
    "            mp_drawing.draw_landmarks(\n",
    "            image=output_frame,\n",
    "            landmark_list=pose_landmarks,\n",
    "            connections=mp_pose.POSE_CONNECTIONS)\n",
    "        output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(images_out_folder, pose_class_name ,image_name), output_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934dd83",
   "metadata": {},
   "source": [
    "# Read data from user camera and populate the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"video.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#pose model\n",
    "with mp_pose.Pose() as pose_tracker:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        result= pose_tracker.process(image)\n",
    "        pose_landmarks = result.pose_landmarks\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "        \n",
    "        try:\n",
    "            pose = pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            pose_row.insert(0, class_name)  \n",
    "            \n",
    "            with open(csv_file_name, mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(pose_row) \n",
    "        except:\n",
    "            pass           \n",
    "        \n",
    "        cv2.imshow('Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c0340",
   "metadata": {},
   "source": [
    "# Add video data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in_folder = 'yoga_poses_videos_in'\n",
    "videos_out_folder = 'yoga_poses_videos_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7e6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pose_class_names = [n for n in os.listdir(videos_in_folder) if not n.startswith('.')]\n",
    "\n",
    "print(pose_class_names)\n",
    "\n",
    "for pose_class_name in pose_class_names:\n",
    "    \n",
    "    video_names = sorted([n for n in os.listdir(os.path.join(videos_in_folder, pose_class_name)) \n",
    "                      if not n.startswith('.')])\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(os.path.join(videos_out_folder, pose_class_name))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "   \n",
    "    for video_name in tqdm.tqdm(video_names, position=0):\n",
    "        \n",
    "        print(f\"Processing {os.path.join(videos_in_folder, pose_class_name, video_name)}\")\n",
    "        \n",
    "        video_cap = cv2.VideoCapture(os.path.join(videos_in_folder, pose_class_name, video_name))\n",
    "\n",
    "        # Get some video parameters to generate output video with classificaiton.\n",
    "        video_n_frames = video_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        video_fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "        video_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        video_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        #out_video = cv2.VideoWriter(os.path.join(videos_out_folder, pose_class_name, video_name[:-4]+'.avi'), cv2.VideoWriter_fourcc(*'MJPG'), video_fps, (video_width, video_height))\n",
    "        output_frame = None\n",
    "        \n",
    "        with mp_pose.Pose() as pose_tracker:\n",
    "            while True:\n",
    "    # Get next frame of the video.\n",
    "                success, frame = video_cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "    # Run pose tracker.\n",
    "                input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                input_frame.flags.writeable = False\n",
    "        \n",
    "                result = pose_tracker.process(image=input_frame)\n",
    "        \n",
    "                input_frame.flags.writeable = True\n",
    "                pose_landmarks = result.pose_landmarks\n",
    "        \n",
    "                input_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "                \n",
    "                try:\n",
    "                    pose = pose_landmarks.landmark\n",
    "                    pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                    pose_row.insert(0, pose_class_name)  \n",
    "            \n",
    "                    with open(\"video_coordinate.csv\", mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        csv_writer.writerow(pose_row) \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # Draw pose prediction.\n",
    "                #output_frame = input_frame.copy()\n",
    "                #if pose_landmarks is not None:\n",
    "                    #mp_drawing.draw_landmarks(\n",
    "                    #image=output_frame,\n",
    "                    #landmark_list=pose_landmarks,\n",
    "                    #connections=mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "                #out_video.write(np.array(output_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"C:\\Dev\\Python\\ML\\MinorModel\\yoga_poses_videos_in\\mountain\\IMG_1111.mov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "video_n_frames = video_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "video_fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "video_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "ret, frame = video_cap.read()\n",
    "\n",
    "out_video = cv2.VideoWriter(\"./yoga_poses_videos_out/test1.avi\", cv2.VideoWriter_fourcc(*'MJPG'), video_fps, (video_width, video_height))\n",
    "with mp_pose.Pose() as pose_tracker:\n",
    "    \n",
    "    while True:\n",
    "        # Get next frame of the video.\n",
    "        success, frame = video_cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        result= pose_tracker.process(image)\n",
    "        pose_landmarks = result.pose_landmarks\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        output_frame = image.copy()\n",
    "        if pose_landmarks is not None:\n",
    "            mp_drawing.draw_landmarks(\n",
    "            image=output_frame,\n",
    "            landmark_list=pose_landmarks,\n",
    "            connections=mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        out_video.write(np.array(output_frame))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb0e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc06c42b",
   "metadata": {},
   "source": [
    "# Starting on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1a700b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffa27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('video_coordinate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "X = df.drop('class', axis = 1) \n",
    "#target\n",
    "y = df['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abe103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08ac5a",
   "metadata": {},
   "source": [
    "# ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rfc':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gbc':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd494461",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35355340",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb85b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rfc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786224af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ef84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat), sep = \": \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713267c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rfc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ccb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a474213",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mid_poses.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rfc'], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb815eb1d048782cc97d23db6955d372697eef8325563321e950dadcbc29d048"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
